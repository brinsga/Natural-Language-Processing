{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Domain-Run-all-Siamese-lstm-question-pairs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPk73r1qgijLbBkQWCAthu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQ0yHF0JyDJ",
        "colab_type": "code",
        "outputId": "9716b17d-c2ec-4664-c231-75588738e1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Implememntation based on: https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9OHjPO0J49b",
        "colab_type": "code",
        "outputId": "6e7c0b5d-fca1-4447-8661-bbaaabfee065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip drive/My\\ Drive/NLP/quora_dataset/test.csv.zip \n",
        "!unzip drive/My\\ Drive/NLP/quora_dataset/train.csv.zip "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/NLP/quora_dataset/test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  drive/My Drive/NLP/quora_dataset/train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8G5aTnqKjmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = 'drive/My Drive/NLP/quora_dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AbF-VPjKqhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(1337)\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten, merge, LSTM, Lambda, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzFVCf4tMlTg",
        "colab_type": "code",
        "outputId": "19a3dc1b-46e3-451c-8e3b-104c4dd63c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fceDPwKwVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_FILE = 'train.csv'\n",
        "TEST_DATA_FILE = 'test.csv'\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "MAX_NB_WORDS = 200000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy975_LTK-K4",
        "colab_type": "code",
        "outputId": "a303bbf3-4f13-4015-b51c-a20b3b58632a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Indexing word vectors.')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(os.path.join(BASE_DIR, 'glove.6B.300d.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMSyjQrDfbxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#embeddings_index['unk'] = np.zeros((300,), dtype=float)\n",
        "embeddings_index['ydahbd'] = np.zeros((300,), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sX7cp4e9ySd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = {}\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/apple/', 'corpus.tsv'), encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.strip().split(\"\\t\")\n",
        "  questions[values[0]] = values[1]\n",
        "\n",
        "f.close()\n",
        "\n",
        "source = []\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/apple/', 'full.pos.txt'), encoding='utf-8')\n",
        "i = 0\n",
        "for line in f:\n",
        "  source.append([])\n",
        "  values = line.strip().split(\" \")\n",
        "  source[i].append('ydahbd '*30)\n",
        "  source[i].append('ydahbd '*30)\n",
        "  source[i].append(questions[values[0]])\n",
        "  source[i].append(questions[values[1]])\n",
        "  source[i].append(questions[values[0]])\n",
        "  source[i].append(questions[values[1]])\n",
        "  source[i].append(1)\n",
        "  i+=1\n",
        "f.close()\n",
        "\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/apple/', 'full.neg.txt'), encoding='utf-8')\n",
        "j = 0\n",
        "\n",
        "for line in f:\n",
        "  if j > 50000:\n",
        "    break\n",
        "  source.append([])\n",
        "  values = line.strip().split(\" \")\n",
        "  source[i].append('ydahbd '*30)\n",
        "  source[i].append('ydahbd '*30)\n",
        "  source[i].append(questions[values[0]])\n",
        "  source[i].append(questions[values[1]])\n",
        "  source[i].append(questions[values[0]])\n",
        "  source[i].append(questions[values[1]])\n",
        "  source[i].append(0)\n",
        "  i+=1\n",
        "  j+=1\n",
        "\n",
        "f.close()\n",
        "\n",
        "data = source"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rniesSJGziFS",
        "colab_type": "code",
        "outputId": "6730a69a-403f-4723-d416-454616ba9cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "source[7000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ',\n",
              " 'ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ydahbd ',\n",
              " 'PDF annotation tools for the iPad',\n",
              " 'Reinstalling my Windows machine and wanting to preserve iTunes backups',\n",
              " 'PDF annotation tools for the iPad',\n",
              " 'Reinstalling my Windows machine and wanting to preserve iTunes backups',\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYzgzLoxDMjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "np.random.shuffle(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lhRuByTEat2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(data[5000:15000])\n",
        "test = np.array(data[:5000])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj9EoNeKldfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data, source"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYC0r8NDElB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_train = list(train[:,0])\n",
        "q2_train = list(train[:,1])\n",
        "q3_train = list(train[:,2])\n",
        "q4_train = list(train[:,3])\n",
        "q5_train = list(train[:,4])\n",
        "q6_train = list(train[:,5])\n",
        "label_train = list(train[:,6])\n",
        "\n",
        "q1_test = list(test[:,0])\n",
        "q2_test = list(test[:,1])\n",
        "q3_test = list(test[:,2])\n",
        "q4_test = list(test[:,3])\n",
        "q5_test = list(test[:,4])\n",
        "q6_test = list(test[:,5])\n",
        "label_test = list(test[:,6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEGmCN3xO3HA",
        "colab_type": "code",
        "outputId": "5e3b15cb-31a2-43e5-e46f-7013f8e3b738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Processing text dataset')\n",
        "texts_1 = [] \n",
        "texts_2 = []\n",
        "labels = []  # list of label ids\n",
        "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    header = next(reader)\n",
        "    for values in reader:\n",
        "        q1_train.append(values[3])\n",
        "        q2_train.append(values[4])\n",
        "        q3_train.append(values[3])\n",
        "        q4_train.append(values[4])\n",
        "        q5_train.append('ydahbd '*30)\n",
        "        q6_train.append('ydahbd '*30)\n",
        "        label_train.append(int(values[5]))\n",
        "print('Found %s texts.' % len(q1_train))\n",
        "\n",
        "test_texts_1 = q1_test\n",
        "test_texts_2 = q2_test\n",
        "test_texts_3 = q3_test\n",
        "test_texts_4 = q4_test\n",
        "test_texts_5 = q5_test\n",
        "test_texts_6 = q6_test\n",
        "test_labels = label_test  # list of label ids\n",
        "\n",
        "print('Found %s texts.' % len(test_texts_1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing text dataset\n",
            "Found 414290 texts.\n",
            "Found 5000 texts.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q355b0Zpsrh8",
        "colab_type": "code",
        "outputId": "ef8a27a3-ec51-469e-c2a9-4d2fcb0270ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(q1_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "414290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AljkwqqcPB0r",
        "colab_type": "code",
        "outputId": "0057a47f-dba9-40ea-aefe-2a0e2caca202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(q1_train + q2_train + q3_train + q4_train)\n",
        "sequences_1 = tokenizer.texts_to_sequences(q1_train)\n",
        "sequences_2 = tokenizer.texts_to_sequences(q2_train)\n",
        "sequences_3 = tokenizer.texts_to_sequences(q3_train)\n",
        "sequences_4 = tokenizer.texts_to_sequences(q4_train)\n",
        "sequences_5 = tokenizer.texts_to_sequences(q5_train)\n",
        "sequences_6 = tokenizer.texts_to_sequences(q6_train)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "test_sequences_1 = tokenizer.texts_to_sequences(q1_test)\n",
        "test_sequences_2 = tokenizer.texts_to_sequences(q2_test)\n",
        "test_sequences_3 = tokenizer.texts_to_sequences(q3_test)\n",
        "test_sequences_4 = tokenizer.texts_to_sequences(q4_test)\n",
        "test_sequences_5 = tokenizer.texts_to_sequences(q5_test)\n",
        "test_sequences_6 = tokenizer.texts_to_sequences(q6_test)\n",
        "\n",
        "\n",
        "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_3 = pad_sequences(sequences_3, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_4 = pad_sequences(sequences_4, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_5 = pad_sequences(sequences_5, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_6 = pad_sequences(sequences_6, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = np.array(label_train)\n",
        "print('Shape of data tensor:', data_1.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_3 = pad_sequences(test_sequences_3, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_4 = pad_sequences(test_sequences_4, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_5 = pad_sequences(test_sequences_5, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_6 = pad_sequences(test_sequences_6, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_labels = np.array(label_test)\n",
        "\n",
        "del test_sequences_1\n",
        "del test_sequences_2\n",
        "del test_sequences_3\n",
        "del test_sequences_4\n",
        "del test_sequences_5\n",
        "del test_sequences_6\n",
        "del sequences_1\n",
        "del sequences_2\n",
        "del sequences_3\n",
        "del sequences_4\n",
        "del sequences_5\n",
        "del sequences_6\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 96729 unique tokens.\n",
            "Shape of data tensor: (414290, 30)\n",
            "Shape of label tensor: (414290,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDQbyxiQhbG",
        "colab_type": "code",
        "outputId": "ceb052e5-32d9-491d-bd30-fa825da2f1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "# prepare embedding matrix\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))+ 2\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n",
            "Null word embeddings: 36068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8c5azlYRNvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(nb_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5pLpyLjSpuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_lstm = np.random.randint(175, 275)\n",
        "num_dense = np.random.randint(100, 150)\n",
        "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
        "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
        "\n",
        "act = 'relu'\n",
        "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F02d_9OaSL1W",
        "colab_type": "code",
        "outputId": "cc8b560b-eb70-4ba6-c9a0-5228b8afbe4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "perm = np.random.permutation(len(data_1))\n",
        "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
        "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
        "\n",
        "data_1_train = data_1[idx_train]\n",
        "data_2_train = data_2[idx_train]\n",
        "data_3_train = data_3[idx_train]\n",
        "data_4_train = data_4[idx_train]\n",
        "data_5_train = data_5[idx_train]\n",
        "data_6_train = data_6[idx_train]\n",
        "\n",
        "labels_train = labels[idx_train]\n",
        "\n",
        "data_1_val = data_1[idx_val]\n",
        "data_2_val = data_2[idx_val]\n",
        "data_3_val = data_3[idx_val]\n",
        "data_4_val = data_4[idx_val]\n",
        "data_5_val = data_5[idx_val]\n",
        "data_6_val = data_6[idx_val]\n",
        "\n",
        "labels_val =labels[idx_val]\n",
        "\n",
        "weight_val = np.ones(len(labels_val))\n",
        "if re_weight:\n",
        "    weight_val *= 0.472001959\n",
        "    weight_val[labels_val==0] = 1.309028344"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxc3FyGNwLpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_train = np.array(labels_train).astype(int).tolist()\n",
        "labels_val = np.array(labels_val).astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbefDzrWTNx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, RNN, GRU\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import keras.backend as K\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArVJwKAvTGy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
        "\n",
        "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
        "x2 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "sequence_3_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_3_input)\n",
        "x3 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "sequence_4_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_4_input)\n",
        "x4 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "sequence_5_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_5_input)\n",
        "x5= lstm_layer(embedded_sequences_2)\n",
        "\n",
        "sequence_6_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_6_input)\n",
        "x6 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "merged = concatenate([x1, x2, x3,x4,x5,x6])\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "merged = Dense(num_dense, activation=act)(merged)\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(merged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbYMXqfTR3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if re_weight:\n",
        "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
        "else:\n",
        "    class_weight = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBe1L7ZTY3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[sequence_1_input, sequence_2_input,sequence_3_input,sequence_4_input,sequence_5_input,sequence_6_input], \\\n",
        "        outputs=preds)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "        optimizer='nadam',\n",
        "        metrics=['acc',get_f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k347tOEOTvuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
        "        rate_drop_dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWLxLjYTZ4A",
        "colab_type": "code",
        "outputId": "76872da6-1892-4cc3-9e59-44d9052f2797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "#model.summary()\n",
        "print(STAMP)\n",
        "\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
        "bst_model_path = STAMP + '.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "hist = model.fit([data_1_train, data_2_train, data_3_train, data_4_train, data_5_train, data_6_train], labels_train, \\\n",
        "        validation_data=([data_1_val, data_2_val, data_3_val,data_4_val,data_5_val,data_6_val], labels_val, weight_val), \\\n",
        "        epochs=200, batch_size=2048, shuffle=True, \\\n",
        "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "model.load_weights(bst_model_path)\n",
        "bst_val_score = min(hist.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm_225_133_0.19_0.27\n",
            "Train on 372861 samples, validate on 41429 samples\n",
            "Epoch 1/200\n",
            "372861/372861 [==============================] - 110s 294us/step - loss: 0.4355 - acc: 0.6897 - get_f1: 0.3917 - val_loss: 0.3075 - val_acc: 0.6560 - val_get_f1: 0.1109\n",
            "Epoch 2/200\n",
            "372861/372861 [==============================] - 107s 286us/step - loss: 0.3460 - acc: 0.7233 - get_f1: 0.4277 - val_loss: 0.2967 - val_acc: 0.6735 - val_get_f1: 0.1981\n",
            "Epoch 3/200\n",
            "372861/372861 [==============================] - 107s 286us/step - loss: 0.3231 - acc: 0.7419 - get_f1: 0.4870 - val_loss: 0.2619 - val_acc: 0.7125 - val_get_f1: 0.3751\n",
            "Epoch 4/200\n",
            "372861/372861 [==============================] - 106s 285us/step - loss: 0.3071 - acc: 0.7555 - get_f1: 0.5290 - val_loss: 0.2176 - val_acc: 0.7646 - val_get_f1: 0.6001\n",
            "Epoch 5/200\n",
            "372861/372861 [==============================] - 106s 283us/step - loss: 0.2931 - acc: 0.7691 - get_f1: 0.5678 - val_loss: 0.2107 - val_acc: 0.7886 - val_get_f1: 0.6354\n",
            "Epoch 6/200\n",
            "372861/372861 [==============================] - 106s 284us/step - loss: 0.2814 - acc: 0.7803 - get_f1: 0.5967 - val_loss: 0.1927 - val_acc: 0.8014 - val_get_f1: 0.6948\n",
            "Epoch 7/200\n",
            "372861/372861 [==============================] - 105s 282us/step - loss: 0.2711 - acc: 0.7892 - get_f1: 0.6190 - val_loss: 0.2156 - val_acc: 0.7932 - val_get_f1: 0.6530\n",
            "Epoch 8/200\n",
            "372861/372861 [==============================] - 105s 283us/step - loss: 0.2617 - acc: 0.7992 - get_f1: 0.6434 - val_loss: 0.1823 - val_acc: 0.8219 - val_get_f1: 0.7352\n",
            "Epoch 9/200\n",
            "372861/372861 [==============================] - 106s 284us/step - loss: 0.2534 - acc: 0.8066 - get_f1: 0.6612 - val_loss: 0.1817 - val_acc: 0.8227 - val_get_f1: 0.7259\n",
            "Epoch 10/200\n",
            "372861/372861 [==============================] - 106s 283us/step - loss: 0.2457 - acc: 0.8144 - get_f1: 0.6791 - val_loss: 0.1769 - val_acc: 0.8227 - val_get_f1: 0.7327\n",
            "Epoch 11/200\n",
            "372861/372861 [==============================] - 105s 282us/step - loss: 0.2392 - acc: 0.8199 - get_f1: 0.6905 - val_loss: 0.1825 - val_acc: 0.8248 - val_get_f1: 0.7328\n",
            "Epoch 12/200\n",
            "372861/372861 [==============================] - 105s 283us/step - loss: 0.2326 - acc: 0.8263 - get_f1: 0.7049 - val_loss: 0.1737 - val_acc: 0.8296 - val_get_f1: 0.7440\n",
            "Epoch 13/200\n",
            "372861/372861 [==============================] - 105s 282us/step - loss: 0.2266 - acc: 0.8326 - get_f1: 0.7179 - val_loss: 0.1783 - val_acc: 0.8313 - val_get_f1: 0.7443\n",
            "Epoch 14/200\n",
            "372861/372861 [==============================] - 105s 283us/step - loss: 0.2210 - acc: 0.8373 - get_f1: 0.7275 - val_loss: 0.1755 - val_acc: 0.8341 - val_get_f1: 0.7532\n",
            "Epoch 15/200\n",
            "372861/372861 [==============================] - 106s 285us/step - loss: 0.2156 - acc: 0.8429 - get_f1: 0.7392 - val_loss: 0.1748 - val_acc: 0.8364 - val_get_f1: 0.7537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdVPWYGPzPE",
        "colab_type": "code",
        "outputId": "5d11f8e0-fc07-403c-9e8a-dd6041b8f94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds = model.predict([test_data_1, test_data_2, test_data_3, test_data_4, test_data_5, test_data_6], batch_size=500, verbose=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 199us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_EXKWbG3L5b",
        "colab_type": "code",
        "outputId": "163eb3e5-f034-41a0-c7c8-6c91f06fc8bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_preds = list(preds)\n",
        "to_check = []\n",
        "print(new_preds[1])\n",
        "for i in range(len(new_preds)):\n",
        "  if new_preds[i][0] > 0.05:\n",
        "    to_check.append(1)\n",
        "  else:\n",
        "    to_check.append(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.8539635e-06]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Fs96P73eQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_labels = np.array(test_labels).astype(int).tolist()\n",
        "acc = 0\n",
        "for i in range(len(to_check)):\n",
        "  if to_check[i] == new_labels[i]:\n",
        "    acc +=1\n",
        "acc = acc/ len(to_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EavVOXoM7_FZ",
        "colab_type": "code",
        "outputId": "2d71571e-8e65-4456-b3d3-83faffc9436d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.943"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FncAUfsd3hUV",
        "colab_type": "code",
        "outputId": "b25f97a1-fa4e-4af3-f328-be2f59d27372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# 0.73346 #1000 training data ---> Run all Siamese\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test = new_labels\n",
        "#y_pred_bool = np.argmax(new_preds, axis=1)\n",
        "y_pred_bool = to_check\n",
        "\n",
        "print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      4749\n",
            "           1       0.43      0.42      0.42       251\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.70      0.69      0.70      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8MSYHJs3kN8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1AEE-IE3lrD",
        "colab_type": "code",
        "outputId": "f229fb0f-45d5-4774-b650-2ebc6697949a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test, y_pred_bool)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6945286866851399"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    }
  ]
}