{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Domain-Adaptation-Siamese-lstm-question-pairs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyML83OVSG21eztLUQo59Glp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brinsga/Natural-Language-Processing/blob/master/Domain_Adaptation_combined_Siamese_lstm_question_pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQ0yHF0JyDJ",
        "colab_type": "code",
        "outputId": "7570b8d7-e7c6-44e1-efd4-fe9f7a2d662a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Implememntation based on: https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9OHjPO0J49b",
        "colab_type": "code",
        "outputId": "dfeda501-d9b2-48f0-8dce-224695a228df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip drive/My\\ Drive/NLP/quora_dataset/test.csv.zip \n",
        "!unzip drive/My\\ Drive/NLP/quora_dataset/train.csv.zip "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/NLP/quora_dataset/test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  drive/My Drive/NLP/quora_dataset/train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8G5aTnqKjmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = 'drive/My Drive/NLP/quora_dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AbF-VPjKqhB",
        "colab_type": "code",
        "outputId": "62da7fb8-7ee3-44af-8100-6a1d0d6662aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(1337)\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten, merge, LSTM, Lambda, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import sys"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzFVCf4tMlTg",
        "colab_type": "code",
        "outputId": "9e4284e7-dddd-438e-fac1-5fd147213e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.200d.txt  glove.6B.50d.txt\tsample_data  train.csv\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\ttest.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fceDPwKwVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_FILE = 'train.csv'\n",
        "TEST_DATA_FILE = 'test.csv'\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "MAX_NB_WORDS = 200000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy975_LTK-K4",
        "colab_type": "code",
        "outputId": "58e193a4-7fd3-4299-c05a-87a09005f68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Indexing word vectors.')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(os.path.join(BASE_DIR, 'glove.6B.300d.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sX7cp4e9ySd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = {}\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/apple/', 'corpus.tsv'), encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.strip().split(\"\\t\")\n",
        "  questions[values[0]] = values[1]\n",
        "\n",
        "f.close()\n",
        "\n",
        "q1,q2,label = [],[],[]\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/apple/', 'full.pos.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.strip().split(\" \")\n",
        "  q1.append(questions[values[0]])\n",
        "  q2.append(questions[values[1]])\n",
        "  label.append(1)\n",
        "f.close()\n",
        "\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/apple/', 'full.neg.txt'), encoding='utf-8')\n",
        "i = 0\n",
        "for line in f:\n",
        "  if i > 50000:\n",
        "    break\n",
        "  values = line.strip().split(\" \")\n",
        "  q1.append(questions[values[0]])\n",
        "  q2.append(questions[values[1]])\n",
        "  label.append(0)\n",
        "  i+=1\n",
        "f.close()\n",
        "\n",
        "data = np.array(list(zip(q1,q2,label)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYzgzLoxDMjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "np.random.shuffle(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lhRuByTEat2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[5000:15000]\n",
        "test = data[:5000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYC0r8NDElB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_train = list(train[:,0])\n",
        "q2_train = list(train[:,1])\n",
        "label_train = list(train[:,2])\n",
        "\n",
        "q1_test = list(test[:,0])\n",
        "q2_test = list(test[:,1])\n",
        "label_test = list(test[:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEGmCN3xO3HA",
        "colab_type": "code",
        "outputId": "32bdac32-7ce5-4e35-fc67-e7e5474e34a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Processing text dataset')\n",
        "texts_1 = [] \n",
        "texts_2 = []\n",
        "labels = []  # list of label ids\n",
        "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    header = next(reader)\n",
        "    for values in reader:\n",
        "        texts_1.append(values[3])\n",
        "        texts_2.append(values[4])\n",
        "        labels.append(int(values[5]))\n",
        "print('Found %s texts.' % len(texts_1))\n",
        "\n",
        "test_texts_1 = q1_test\n",
        "test_texts_2 = q2_test\n",
        "test_labels = label_test  # list of label ids\n",
        "\n",
        "print('Found %s texts.' % len(test_texts_1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing text dataset\n",
            "Found 404290 texts.\n",
            "Found 5000 texts.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AljkwqqcPB0r",
        "colab_type": "code",
        "outputId": "e6d2b0bf-dccd-4447-ff5e-0571d403ccb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts_1 + texts_2)\n",
        "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
        "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
        "test_sequences_2 = tokenizer.texts_to_sequences(test_texts_2)\n",
        "\n",
        "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = np.array(labels)\n",
        "print('Shape of data tensor:', data_1.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_labels = np.array(test_labels)\n",
        "del test_sequences_1\n",
        "del test_sequences_2\n",
        "del sequences_1\n",
        "del sequences_2\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 95596 unique tokens.\n",
            "Shape of data tensor: (404290, 30)\n",
            "Shape of label tensor: (404290,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDQbyxiQhbG",
        "colab_type": "code",
        "outputId": "ecceeefb-e8be-461a-9121-10bbf2137b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "# prepare embedding matrix\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n",
            "Null word embeddings: 35260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8c5azlYRNvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(nb_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5pLpyLjSpuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_lstm = np.random.randint(175, 275)\n",
        "num_dense = np.random.randint(100, 150)\n",
        "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
        "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
        "\n",
        "act = 'relu'\n",
        "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F02d_9OaSL1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perm = np.random.permutation(len(data_1))\n",
        "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
        "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
        "\n",
        "data_1_train = data_1[idx_train]\n",
        "data_2_train = data_2[idx_train]\n",
        "labels_train = labels[idx_train]\n",
        "\n",
        "data_1_val = data_1[idx_val]\n",
        "data_2_val = data_2[idx_val]\n",
        "labels_val = labels[idx_val]\n",
        "\n",
        "weight_val = np.ones(len(labels_val))\n",
        "if re_weight:\n",
        "    weight_val *= 0.472001959\n",
        "    weight_val[labels_val==0] = 1.309028344"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbefDzrWTNx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, RNN, GRU\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import keras.backend as K\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArVJwKAvTGy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
        "\n",
        "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
        "y1 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "merged = concatenate([x1, y1])\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "merged = Dense(num_dense, activation=act)(merged)\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(merged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbYMXqfTR3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if re_weight:\n",
        "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
        "else:\n",
        "    class_weight = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBe1L7ZTY3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[sequence_1_input, sequence_2_input], \\\n",
        "        outputs=preds)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "        optimizer='nadam',\n",
        "        metrics=['acc',get_f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k347tOEOTvuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
        "        rate_drop_dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWLxLjYTZ4A",
        "colab_type": "code",
        "outputId": "eceb557c-21a0-4b66-f10c-069f3c8d938b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "#model.summary()\n",
        "print(STAMP)\n",
        "\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
        "bst_model_path = STAMP + '.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "hist = model.fit([data_1_train, data_2_train], labels_train, \\\n",
        "        validation_data=([data_1_val, data_2_val], labels_val, weight_val), \\\n",
        "        epochs=200, batch_size=2048, shuffle=True, \\\n",
        "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "model.load_weights(bst_model_path)\n",
        "bst_val_score = min(hist.history['val_loss'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm_225_125_0.33_0.39\n",
            "Train on 363861 samples, validate on 40429 samples\n",
            "Epoch 1/200\n",
            "363861/363861 [==============================] - 40s 109us/step - loss: 0.4754 - acc: 0.6594 - get_f1: 0.3353 - val_loss: 0.3960 - val_acc: 0.6552 - val_get_f1: 0.1343\n",
            "Epoch 2/200\n",
            "363861/363861 [==============================] - 39s 108us/step - loss: 0.3808 - acc: 0.6894 - get_f1: 0.3189 - val_loss: 0.3617 - val_acc: 0.6893 - val_get_f1: 0.3003\n",
            "Epoch 3/200\n",
            "363861/363861 [==============================] - 39s 107us/step - loss: 0.3628 - acc: 0.7050 - get_f1: 0.3794 - val_loss: 0.3431 - val_acc: 0.7250 - val_get_f1: 0.4476\n",
            "Epoch 4/200\n",
            "363861/363861 [==============================] - 38s 104us/step - loss: 0.3510 - acc: 0.7159 - get_f1: 0.4183 - val_loss: 0.3341 - val_acc: 0.7364 - val_get_f1: 0.4874\n",
            "Epoch 5/200\n",
            "363861/363861 [==============================] - 38s 103us/step - loss: 0.3413 - acc: 0.7236 - get_f1: 0.4428 - val_loss: 0.3260 - val_acc: 0.7490 - val_get_f1: 0.5321\n",
            "Epoch 6/200\n",
            "363861/363861 [==============================] - 37s 101us/step - loss: 0.3333 - acc: 0.7308 - get_f1: 0.4655 - val_loss: 0.3161 - val_acc: 0.7514 - val_get_f1: 0.5364\n",
            "Epoch 7/200\n",
            "363861/363861 [==============================] - 37s 102us/step - loss: 0.3270 - acc: 0.7362 - get_f1: 0.4820 - val_loss: 0.3117 - val_acc: 0.7573 - val_get_f1: 0.5539\n",
            "Epoch 8/200\n",
            "363861/363861 [==============================] - 37s 102us/step - loss: 0.3216 - acc: 0.7410 - get_f1: 0.4972 - val_loss: 0.3121 - val_acc: 0.7704 - val_get_f1: 0.6034\n",
            "Epoch 9/200\n",
            "363861/363861 [==============================] - 38s 103us/step - loss: 0.3170 - acc: 0.7457 - get_f1: 0.5107 - val_loss: 0.3067 - val_acc: 0.7582 - val_get_f1: 0.5514\n",
            "Epoch 10/200\n",
            "363861/363861 [==============================] - 38s 103us/step - loss: 0.3132 - acc: 0.7499 - get_f1: 0.5226 - val_loss: 0.3054 - val_acc: 0.7710 - val_get_f1: 0.5947\n",
            "Epoch 11/200\n",
            "363861/363861 [==============================] - 37s 102us/step - loss: 0.3091 - acc: 0.7540 - get_f1: 0.5340 - val_loss: 0.3035 - val_acc: 0.7758 - val_get_f1: 0.6110\n",
            "Epoch 12/200\n",
            "363861/363861 [==============================] - 38s 103us/step - loss: 0.3060 - acc: 0.7565 - get_f1: 0.5415 - val_loss: 0.3031 - val_acc: 0.7816 - val_get_f1: 0.6267\n",
            "Epoch 13/200\n",
            "363861/363861 [==============================] - 37s 102us/step - loss: 0.3027 - acc: 0.7600 - get_f1: 0.5505 - val_loss: 0.3006 - val_acc: 0.7819 - val_get_f1: 0.6266\n",
            "Epoch 14/200\n",
            "363861/363861 [==============================] - 38s 104us/step - loss: 0.2996 - acc: 0.7625 - get_f1: 0.5573 - val_loss: 0.2956 - val_acc: 0.7814 - val_get_f1: 0.6207\n",
            "Epoch 15/200\n",
            "363861/363861 [==============================] - 38s 103us/step - loss: 0.2969 - acc: 0.7660 - get_f1: 0.5671 - val_loss: 0.2919 - val_acc: 0.7789 - val_get_f1: 0.6105\n",
            "Epoch 16/200\n",
            "363861/363861 [==============================] - 37s 101us/step - loss: 0.2943 - acc: 0.7682 - get_f1: 0.5730 - val_loss: 0.2931 - val_acc: 0.7868 - val_get_f1: 0.6357\n",
            "Epoch 17/200\n",
            "363861/363861 [==============================] - 37s 102us/step - loss: 0.2919 - acc: 0.7707 - get_f1: 0.5793 - val_loss: 0.2879 - val_acc: 0.7819 - val_get_f1: 0.6179\n",
            "Epoch 18/200\n",
            "363861/363861 [==============================] - 38s 103us/step - loss: 0.2907 - acc: 0.7718 - get_f1: 0.5817 - val_loss: 0.2849 - val_acc: 0.7834 - val_get_f1: 0.6208\n",
            "Epoch 19/200\n",
            "363861/363861 [==============================] - 37s 103us/step - loss: 0.2881 - acc: 0.7740 - get_f1: 0.5877 - val_loss: 0.2871 - val_acc: 0.7849 - val_get_f1: 0.6250\n",
            "Epoch 20/200\n",
            "363861/363861 [==============================] - 37s 102us/step - loss: 0.2867 - acc: 0.7751 - get_f1: 0.5907 - val_loss: 0.2874 - val_acc: 0.7897 - val_get_f1: 0.6399\n",
            "Epoch 21/200\n",
            "363861/363861 [==============================] - 38s 105us/step - loss: 0.2843 - acc: 0.7781 - get_f1: 0.5983 - val_loss: 0.2943 - val_acc: 0.7973 - val_get_f1: 0.6659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdVPWYGPzPE",
        "colab_type": "code",
        "outputId": "a08079a2-e509-4c88-9623-8b215aa92643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds = model.predict([test_data_1, test_data_2], batch_size=500, verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 0s 80us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-waDgRFQJQJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_labels = np.array(test_labels).astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKd2EGUxOyGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7cfd4f2-f801-41ba-d720-419997b35300"
      },
      "source": [
        "new_preds = list(preds)\n",
        "to_check = []\n",
        "print(new_preds[1])\n",
        "for i in range(len(new_preds)):\n",
        "  if new_preds[i][0] > 0.1:\n",
        "    to_check.append(1)\n",
        "  else:\n",
        "    to_check.append(0)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03323421]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiQZZ7o-SNHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_labels = list(new_labels)\n",
        "acc = 0\n",
        "for i in range(len(to_check)):\n",
        "  if to_check[i] == new_labels[i]:\n",
        "    acc +=1\n",
        "acc = acc/ len(to_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV4B7TLQUXbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f11ac9c-45a2-4cd4-cb27-17d70861f977"
      },
      "source": [
        "#acc = 0.769\n",
        "acc"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iEeXQ7EHQ4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bb0d2c2e-2660-4629-efc6-d656eb5ad620"
      },
      "source": [
        "# 0.73346 #1000 training data\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test = list(np.array(new_labels).astype(int))\n",
        "#y_pred_bool = np.argmax(new_preds, axis=1)\n",
        "y_pred_bool = to_check\n",
        "\n",
        "print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94      4794\n",
            "           1       0.11      0.26      0.15       206\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.54      0.58      0.55      5000\n",
            "weighted avg       0.93      0.88      0.91      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO-VhpMUZEUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffddd601-1d8c-482a-8aea-f8b5cad1a517"
      },
      "source": [
        "#0.55\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test, y_pred_bool)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.584001644450385"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    }
  ]
}