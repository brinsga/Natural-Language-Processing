{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stackoverflow-Siamese-lstm-question-pairs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brinsga/Natural-Language-Processing/blob/master/Stackoverflow_siamese_lstm_question_pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQ0yHF0JyDJ",
        "colab_type": "code",
        "outputId": "ff145ea4-10e2-49fa-99c0-bb745f39bd9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Implememntation based on: https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9OHjPO0J49b",
        "colab_type": "code",
        "outputId": "84cbabf9-be88-4117-c880-fe690da9d991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip drive/My\\ Drive/NLP/quora_dataset/test.csv.zip \n",
        "!unzip drive/My\\ Drive/NLP/quora_dataset/train.csv.zip "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/NLP/quora_dataset/test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  drive/My Drive/NLP/quora_dataset/train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AbF-VPjKqhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80c8d42d-acd5-43fa-a801-2d81ecc0ee5f"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(1337)\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten, merge, LSTM, Lambda, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import sys"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzFVCf4tMlTg",
        "colab_type": "code",
        "outputId": "79d37663-dab8-4d86-a66d-0c68d121353b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t\t   lstm_272_114_0.32_0.25.h5  test.csv\n",
            "lstm_198_128_0.20_0.29.h5  sample_data\t\t      train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fceDPwKwVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_FILE = 'train.csv'\n",
        "TEST_DATA_FILE = 'test.csv'\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "MAX_NB_WORDS = 200000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M797KLhQ7cfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = 'drive/My Drive/NLP/quora_dataset/apple/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzF2d2oR8aKh",
        "colab_type": "code",
        "outputId": "dc910477-a348-489f-88af-3db16a415001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls drive/My\\ Drive/NLP/quora_dataset/apple"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus_domain.tsv  corpus.tsv.gz  dev.pos.txt\tfull.pos.txt  test.pos.txt\n",
            "corpus.tsv\t   dev.neg.txt\t  full.neg.txt\ttest.neg.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eLuSvzc7dZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = {}\n",
        "f = codecs.open(os.path.join(BASE_DIR, 'corpus.tsv'), encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.strip().split(\"\\t\")\n",
        "  questions[values[0]] = values[1]\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_i9Nw5T7dfY",
        "colab_type": "code",
        "outputId": "956cf6a5-4a1e-4d74-cabe-ebf1285b3531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(questions)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80466"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-mzqAub7djZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1,q2,label = [],[],[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj6tJmOS7diA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = codecs.open(os.path.join(BASE_DIR, 'full.pos.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.strip().split(\" \")\n",
        "  q1.append(questions[values[0]])\n",
        "  q2.append(questions[values[1]])\n",
        "  label.append(1)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvkDh-SU_yvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = codecs.open(os.path.join(BASE_DIR, 'full.neg.txt'), encoding='utf-8')\n",
        "i = 0\n",
        "for line in f:\n",
        "  if i > 50000:\n",
        "    break\n",
        "  values = line.strip().split(\" \")\n",
        "  q1.append(questions[values[0]])\n",
        "  q2.append(questions[values[1]])\n",
        "  label.append(0)\n",
        "  i+=1\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7UYiRd-9UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(list(zip(q1,q2,label)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBQstAvH-9Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "np.random.shuffle(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDiS7FPV_JG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[5000:15000]\n",
        "test = data[:5000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy975_LTK-K4",
        "colab_type": "code",
        "outputId": "191b20f4-8fce-4c23-cddc-b9277f8597c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Indexing word vectors.')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(os.path.join('drive/My Drive/NLP/quora_dataset/', 'glove.6B.300d.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEGmCN3xO3HA",
        "colab_type": "code",
        "outputId": "39e4b095-b157-443e-ab6b-c8443388c172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Processing text dataset')\n",
        "texts_1 = list(train[:,0])\n",
        "texts_2 = list(train[:,1])\n",
        "labels = np.array(train[:,2]).astype(int).tolist()\n",
        "\n",
        "test_texts_1 = list(test[:,0])\n",
        "test_texts_2 = list(test[:,1])\n",
        "test_labels = np.array(test[:,2]).astype(int).tolist()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing text dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AljkwqqcPB0r",
        "colab_type": "code",
        "outputId": "7fe3da11-2453-4331-ee90-bf4cd077e521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts_1 + texts_2)\n",
        "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
        "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
        "test_sequences_2 = tokenizer.texts_to_sequences(test_texts_2)\n",
        "\n",
        "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = np.array(labels)\n",
        "print('Shape of data tensor:', data_1.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_labels = np.array(test_labels)\n",
        "del test_sequences_1\n",
        "del test_sequences_2\n",
        "del sequences_1\n",
        "del sequences_2\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 6804 unique tokens.\n",
            "Shape of data tensor: (10000, 30)\n",
            "Shape of label tensor: (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDQbyxiQhbG",
        "colab_type": "code",
        "outputId": "d3b05b47-8afd-4ce7-ffc3-4422d0a01882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "# prepare embedding matrix\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n",
            "Null word embeddings: 1030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8c5azlYRNvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(nb_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5pLpyLjSpuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_lstm = np.random.randint(175, 275)\n",
        "num_dense = np.random.randint(100, 150)\n",
        "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
        "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
        "\n",
        "act = 'relu'\n",
        "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F02d_9OaSL1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perm = np.random.permutation(len(data_1))\n",
        "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
        "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
        "\n",
        "data_1_train = data_1[idx_train]\n",
        "data_2_train = data_2[idx_train]\n",
        "labels_train = labels[idx_train]\n",
        "\n",
        "data_1_val = data_1[idx_val]\n",
        "data_2_val = data_2[idx_val]\n",
        "labels_val = labels[idx_val]\n",
        "\n",
        "weight_val = np.ones(len(labels_val))\n",
        "if re_weight:\n",
        "    weight_val *= 0.472001959\n",
        "    weight_val[labels_val==0] = 1.309028344"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbefDzrWTNx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import keras.backend as K\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArVJwKAvTGy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
        "\n",
        "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
        "y1 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "merged = concatenate([x1, y1])\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "merged = Dense(num_dense, activation=act)(merged)\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(merged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbYMXqfTR3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if re_weight:\n",
        "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
        "else:\n",
        "    class_weight = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBe1L7ZTY3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[sequence_1_input, sequence_2_input], \\\n",
        "        outputs=preds)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "        optimizer='nadam',\n",
        "        metrics=['acc',get_f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k347tOEOTvuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
        "        rate_drop_dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWLxLjYTZ4A",
        "colab_type": "code",
        "outputId": "4c3e87a9-e6fd-49cf-a0cd-6893589b30fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model.summary()\n",
        "print(STAMP)\n",
        "\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
        "bst_model_path = STAMP + '.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "hist = model.fit([data_1_train, data_2_train], labels_train, \\\n",
        "        validation_data=([data_1_val, data_2_val], labels_val, weight_val), \\\n",
        "        epochs=200, batch_size=2048, shuffle=True, \\\n",
        "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "model.load_weights(bst_model_path)\n",
        "bst_val_score = min(hist.history['val_loss'])"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm_236_140_0.21_0.15\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/200\n",
            "9000/9000 [==============================] - 3s 348us/step - loss: 1.0672 - acc: 0.5146 - get_f1: 0.0779 - val_loss: 0.8158 - val_acc: 0.9490 - val_get_f1: 0.0727\n",
            "Epoch 2/200\n",
            "9000/9000 [==============================] - 2s 206us/step - loss: 0.8951 - acc: 0.5711 - get_f1: 0.0992 - val_loss: 0.7947 - val_acc: 0.9600 - val_get_f1: 0.0476\n",
            "Epoch 3/200\n",
            "9000/9000 [==============================] - 2s 207us/step - loss: 0.8182 - acc: 0.6324 - get_f1: 0.1215 - val_loss: 0.6970 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 4/200\n",
            "9000/9000 [==============================] - 2s 206us/step - loss: 0.7458 - acc: 0.6906 - get_f1: 0.1341 - val_loss: 0.6479 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 5/200\n",
            "9000/9000 [==============================] - 2s 207us/step - loss: 0.6741 - acc: 0.7559 - get_f1: 0.1625 - val_loss: 0.5826 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 6/200\n",
            "9000/9000 [==============================] - 2s 205us/step - loss: 0.6051 - acc: 0.8106 - get_f1: 0.1987 - val_loss: 0.5120 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 7/200\n",
            "9000/9000 [==============================] - 2s 211us/step - loss: 0.5437 - acc: 0.8406 - get_f1: 0.2017 - val_loss: 0.4393 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 8/200\n",
            "9000/9000 [==============================] - 2s 207us/step - loss: 0.4718 - acc: 0.8807 - get_f1: 0.2516 - val_loss: 0.3769 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 9/200\n",
            "9000/9000 [==============================] - 2s 205us/step - loss: 0.4078 - acc: 0.9098 - get_f1: 0.3041 - val_loss: 0.3129 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 10/200\n",
            "9000/9000 [==============================] - 2s 208us/step - loss: 0.3364 - acc: 0.9359 - get_f1: 0.3702 - val_loss: 0.2662 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 11/200\n",
            "9000/9000 [==============================] - 2s 211us/step - loss: 0.2813 - acc: 0.9486 - get_f1: 0.3721 - val_loss: 0.2268 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 12/200\n",
            "9000/9000 [==============================] - 2s 207us/step - loss: 0.2365 - acc: 0.9564 - get_f1: 0.3888 - val_loss: 0.1912 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 13/200\n",
            "9000/9000 [==============================] - 2s 211us/step - loss: 0.2006 - acc: 0.9618 - get_f1: 0.4598 - val_loss: 0.1595 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 14/200\n",
            "9000/9000 [==============================] - 2s 208us/step - loss: 0.1652 - acc: 0.9671 - get_f1: 0.4954 - val_loss: 0.1428 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 15/200\n",
            "9000/9000 [==============================] - 2s 205us/step - loss: 0.1455 - acc: 0.9679 - get_f1: 0.4718 - val_loss: 0.1302 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 16/200\n",
            "9000/9000 [==============================] - 2s 212us/step - loss: 0.1242 - acc: 0.9730 - get_f1: 0.5712 - val_loss: 0.1139 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 17/200\n",
            "9000/9000 [==============================] - 2s 207us/step - loss: 0.1088 - acc: 0.9724 - get_f1: 0.5250 - val_loss: 0.1057 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 18/200\n",
            "9000/9000 [==============================] - 2s 208us/step - loss: 0.0939 - acc: 0.9762 - get_f1: 0.6182 - val_loss: 0.0995 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 19/200\n",
            "9000/9000 [==============================] - 2s 209us/step - loss: 0.0858 - acc: 0.9758 - get_f1: 0.6227 - val_loss: 0.0958 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 20/200\n",
            "9000/9000 [==============================] - 2s 210us/step - loss: 0.0757 - acc: 0.9769 - get_f1: 0.6205 - val_loss: 0.0927 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 21/200\n",
            "9000/9000 [==============================] - 2s 212us/step - loss: 0.0672 - acc: 0.9789 - get_f1: 0.6693 - val_loss: 0.0900 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 22/200\n",
            "9000/9000 [==============================] - 2s 215us/step - loss: 0.0610 - acc: 0.9809 - get_f1: 0.7129 - val_loss: 0.0872 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 23/200\n",
            "9000/9000 [==============================] - 2s 211us/step - loss: 0.0569 - acc: 0.9824 - get_f1: 0.7448 - val_loss: 0.0863 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 24/200\n",
            "9000/9000 [==============================] - 2s 203us/step - loss: 0.0528 - acc: 0.9830 - get_f1: 0.7463 - val_loss: 0.0855 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 25/200\n",
            "9000/9000 [==============================] - 2s 207us/step - loss: 0.0461 - acc: 0.9858 - get_f1: 0.7996 - val_loss: 0.0851 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 26/200\n",
            "9000/9000 [==============================] - 2s 210us/step - loss: 0.0449 - acc: 0.9854 - get_f1: 0.8033 - val_loss: 0.0849 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 27/200\n",
            "9000/9000 [==============================] - 2s 210us/step - loss: 0.0406 - acc: 0.9871 - get_f1: 0.8201 - val_loss: 0.0842 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 28/200\n",
            "9000/9000 [==============================] - 2s 209us/step - loss: 0.0372 - acc: 0.9871 - get_f1: 0.8119 - val_loss: 0.0843 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 29/200\n",
            "9000/9000 [==============================] - 2s 211us/step - loss: 0.0343 - acc: 0.9896 - get_f1: 0.8537 - val_loss: 0.0847 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n",
            "Epoch 30/200\n",
            "9000/9000 [==============================] - 2s 208us/step - loss: 0.0326 - acc: 0.9886 - get_f1: 0.8360 - val_loss: 0.0847 - val_acc: 0.9630 - val_get_f1: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdVPWYGPzPE",
        "colab_type": "code",
        "outputId": "e3da77af-c202-4df0-b151-6770b1091186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds = model.predict([test_data_1, test_data_2], batch_size=500, verbose=1)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 150us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQnWUyeD-gXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_labels)\n",
        "new_labels = test_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOMi-W2X-geW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74ae519c-aaeb-4862-e26c-8b93d35dacca"
      },
      "source": [
        "new_preds = list(preds)\n",
        "to_check = []\n",
        "print(new_preds[1])\n",
        "for i in range(len(new_preds)):\n",
        "  if new_preds[i][0] > 0.3:\n",
        "    to_check.append(1)\n",
        "  else:\n",
        "    to_check.append(0)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01034416]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0WkjFJUDPbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56789109-c90a-4169-980e-7530a4c6d177"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(new_labels, to_check)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5039840637450199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJlLuAvIDkIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68c0550d-c91d-44bc-a114-566e5d5697a3"
      },
      "source": [
        "len(new_labels)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw-IfySh-gk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = 0\n",
        "for i in range(len(to_check)):\n",
        "  if to_check[i] == new_labels[i]:\n",
        "    acc +=1\n",
        "acc = acc/ len(to_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvceitxRB-d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "981646be-b17d-4709-9963-1750ff8e4e99"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(new_labels, to_check))"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      4749\n",
            "           1       1.00      0.01      0.02       251\n",
            "\n",
            "    accuracy                           0.95      5000\n",
            "   macro avg       0.98      0.50      0.50      5000\n",
            "weighted avg       0.95      0.95      0.93      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-pkc8pQD8xV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be2d1b05-d33a-4a67-e616-fb3f9f818912"
      },
      "source": [
        "acc"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5LPYYEdo4i8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}